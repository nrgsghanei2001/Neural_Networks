{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Classifier\n",
    "\n",
    "This class implements properties of a perceptron classifier. It first initializes needed values like learning rate and input data points and weights matrix which represents coefficients of equation of the plane.\n",
    "\n",
    "In train method, network iterates on input data and adjust weights to separate points with labels 1 and -1. The training process is as below:\n",
    "\n",
    "Prediction:\n",
    "$$label = 1: w\\times x+bias\\gt 0$$\n",
    "$$label = 0: w\\times x+bias\\le 0$$\n",
    "\n",
    "Error Calculation:\n",
    "$$error = TrueLabel - PredLabel$$\n",
    "\n",
    "weight update:\n",
    "$$w = w + \\lambda\\times error\\times x$$\n",
    "$$bias = bias + \\lambda\\times error$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, data, lr=0.01, max_epochs=100):\n",
    "        self.data = data\n",
    "        self.learning_rate = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.weights = np.array([-1, -1, -1], dtype=float)\n",
    "        self.bias = 0\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.max_epochs):\n",
    "            total_error = 0\n",
    "            for point in self.data:\n",
    "\n",
    "                # calculate the weighted sum: ws = w * x + b\n",
    "                weighted_sum = np.dot(self.weights, point[:-1]) + self.bias\n",
    "\n",
    "                # activation function\n",
    "                output = self.activation_function(weighted_sum)\n",
    "\n",
    "                # calculate the error\n",
    "                error = point[-1] - output\n",
    "\n",
    "                # update weights and bias\n",
    "                self.weights += self.learning_rate * error * point[:-1]\n",
    "                self.bias += self.learning_rate * error\n",
    "\n",
    "                # calculate total false predictions\n",
    "                total_error += 1 if error>0 else 0\n",
    "            print(f\"Epoch {epoch+1}: Total Error: {total_error}\")\n",
    "\n",
    "            # If no error in all data points, the data is perfectly classified\n",
    "            if total_error == 0:\n",
    "                print(f\"Training completed after {epoch + 1} epochs\")\n",
    "                break\n",
    "\n",
    "    def test(self, point):\n",
    "        weighted_sum = np.dot(self.weights, point) + self.bias\n",
    "        return self.activation_function(weighted_sum)\n",
    "    \n",
    "\n",
    "    def activation_function(self, ws):\n",
    "        return 1 if ws > 0 else -1\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"dataset/Q1data.csv\"\n",
    "\n",
    "# read the CSV file and convert it to a numpy array\n",
    "df = pd.read_csv(address)\n",
    "data = df.to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error: 17\n",
      "Epoch 2: Total Error: 3\n",
      "Epoch 3: Total Error: 11\n",
      "Epoch 4: Total Error: 8\n",
      "Epoch 5: Total Error: 5\n",
      "Epoch 6: Total Error: 4\n",
      "Epoch 7: Total Error: 5\n",
      "Epoch 8: Total Error: 4\n",
      "Epoch 9: Total Error: 3\n",
      "Epoch 10: Total Error: 0\n",
      "Training completed after 10 epochs\n",
      "[ 35.50837653 -67.43365565   9.65135   ]\n"
     ]
    }
   ],
   "source": [
    "pc = Perceptron(data, lr=0.01, max_epochs=1000)\n",
    "pc.train()\n",
    "print(pc.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda=0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error: 14\n",
      "Epoch 2: Total Error: 9\n",
      "Epoch 3: Total Error: 14\n",
      "Epoch 4: Total Error: 5\n",
      "Epoch 5: Total Error: 6\n",
      "Epoch 6: Total Error: 4\n",
      "Epoch 7: Total Error: 0\n",
      "Training completed after 7 epochs\n",
      "[ 323.35805421 -611.71021479   94.48523239]\n"
     ]
    }
   ],
   "source": [
    "pc = Perceptron(data, lr=0.1, max_epochs=1000)\n",
    "pc.train()\n",
    "print(pc.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error: 15\n",
      "Epoch 2: Total Error: 16\n",
      "Epoch 3: Total Error: 2\n",
      "Epoch 4: Total Error: 8\n",
      "Epoch 5: Total Error: 6\n",
      "Epoch 6: Total Error: 5\n",
      "Epoch 7: Total Error: 3\n",
      "Epoch 8: Total Error: 4\n",
      "Epoch 9: Total Error: 2\n",
      "Epoch 10: Total Error: 2\n",
      "Epoch 11: Total Error: 4\n",
      "Epoch 12: Total Error: 2\n",
      "Epoch 13: Total Error: 2\n",
      "Epoch 14: Total Error: 0\n",
      "Training completed after 14 epochs\n",
      "[ 2186.87605612 -4134.55375094   581.57066097]\n"
     ]
    }
   ],
   "source": [
    "pc = Perceptron(data, lr=0.5, max_epochs=1000)\n",
    "pc.train()\n",
    "print(pc.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error: 15\n",
      "Epoch 2: Total Error: 16\n",
      "Epoch 3: Total Error: 2\n",
      "Epoch 4: Total Error: 8\n",
      "Epoch 5: Total Error: 6\n",
      "Epoch 6: Total Error: 5\n",
      "Epoch 7: Total Error: 3\n",
      "Epoch 8: Total Error: 4\n",
      "Epoch 9: Total Error: 2\n",
      "Epoch 10: Total Error: 2\n",
      "Epoch 11: Total Error: 2\n",
      "Epoch 12: Total Error: 5\n",
      "Epoch 13: Total Error: 4\n",
      "Epoch 14: Total Error: 5\n",
      "Epoch 15: Total Error: 3\n",
      "Epoch 16: Total Error: 1\n",
      "Epoch 17: Total Error: 3\n",
      "Epoch 18: Total Error: 4\n",
      "Epoch 19: Total Error: 3\n",
      "Epoch 20: Total Error: 0\n",
      "Training completed after 20 epochs\n",
      "[  9854.1813211  -18687.45344162   2709.78170996]\n"
     ]
    }
   ],
   "source": [
    "pc = Perceptron(data, lr=2, max_epochs=1000)\n",
    "pc.train()\n",
    "print(pc.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error: 15\n",
      "Epoch 2: Total Error: 16\n",
      "Epoch 3: Total Error: 2\n",
      "Epoch 4: Total Error: 8\n",
      "Epoch 5: Total Error: 6\n",
      "Epoch 6: Total Error: 5\n",
      "Epoch 7: Total Error: 3\n",
      "Epoch 8: Total Error: 4\n",
      "Epoch 9: Total Error: 2\n",
      "Epoch 10: Total Error: 2\n",
      "Epoch 11: Total Error: 2\n",
      "Epoch 12: Total Error: 5\n",
      "Epoch 13: Total Error: 4\n",
      "Epoch 14: Total Error: 5\n",
      "Epoch 15: Total Error: 3\n",
      "Epoch 16: Total Error: 1\n",
      "Epoch 17: Total Error: 3\n",
      "Epoch 18: Total Error: 4\n",
      "Epoch 19: Total Error: 3\n",
      "Epoch 20: Total Error: 0\n",
      "Training completed after 20 epochs\n",
      "[  73912.85990821 -140149.40081216   20329.86282472]\n"
     ]
    }
   ],
   "source": [
    "pc = Perceptron(data, lr=15, max_epochs=1000)\n",
    "pc.train()\n",
    "print(pc.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training network with different $\\lambda$ values, we can see that when $\\lambda$ is too small like 0.01 simulation takes a bit longer. $\\lambda=0.1$ has the best result and finishes in 7 epochs. for larger values of $\\lambda=0.5, 2, 10$ it gets worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
