{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for data preparation and class calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    # define class attributes and objects and initialize them\n",
    "    def __init__(self, hls=1000, ols=2, ne=1000, lr=0.01):\n",
    "        self.input_layer_size = None\n",
    "        self.hidden_layer_size = hls\n",
    "        self.output_layer_size = ols\n",
    "        self.learning_rate = lr\n",
    "        self.W1 = None\n",
    "        self.W2 = None\n",
    "        self.b1 = None\n",
    "        self.b2 = None\n",
    "        self.Z1 = None\n",
    "        self.Z2 = None\n",
    "        self.A1 = None\n",
    "        self.A2 = None\n",
    "        self.dW1 = None\n",
    "        self.dW2 = None\n",
    "        self.db1 = None\n",
    "        self.db2 = None\n",
    "        self.num_epochs = ne\n",
    "\n",
    "    # spilt the data to train and test sets\n",
    "    def data_split(self):\n",
    "        np.random.seed(42)\n",
    "        X, y = make_gaussian_quantiles(n_samples=300, n_features=8, n_classes=2, random_state=42)\n",
    "        y = np.eye(2)[y]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.input_layer_size = self.X_train.shape[1]\n",
    "\n",
    "    # initialize weights randomely\n",
    "    def weight_initialization(self):\n",
    "        self.W1 = np.random.randn(self.input_layer_size, self.hidden_layer_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_layer_size))\n",
    "        self.W2 = np.random.randn(self.hidden_layer_size, self.output_layer_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_layer_size))\n",
    "\n",
    "    # train the weights on model\n",
    "    def train(self):\n",
    "\n",
    "        for e in range(self.num_epochs):\n",
    "            self.forward_propagation()\n",
    "            mse = self.MSE()\n",
    "            self.backward_propagation()\n",
    "            self.weight_update()\n",
    "\n",
    "            if e % 300 == 0:  # report the results in each 50 iterations\n",
    "                print(f\"epoch {e}, train loss: {mse}\")\n",
    "\n",
    "    # forward pass\n",
    "    def forward_propagation(self):\n",
    "        self.Z1 = np.dot( self.X_train, self.W1) + self.b1\n",
    "        self.A1 = self.relu(self.Z1)\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.sigmoid(self.Z2)\n",
    "\n",
    "\n",
    "    # backward pass and propagating error\n",
    "    def backward_propagation(self):\n",
    "\n",
    "        m = self.X_train.shape[0]\n",
    "        dZ2 = self.A2 - self.y_train\n",
    "        self.dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        self.db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * np.where(self.Z1 > 0, 1, 0)\n",
    "        self.dW1 = np.dot(self.X_train.T, dZ1) / m\n",
    "        self.db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    \n",
    "\n",
    "    # calculate error\n",
    "    def MSE(self):\n",
    "        return np.mean((self.y_train - self.A2)**2)\n",
    "\n",
    "    # update weights after each iteration\n",
    "    def weight_update(self):\n",
    "        self.W1 -= self.learning_rate * self.dW1\n",
    "        self.b1 -= self.learning_rate * self.db1\n",
    "        self.W2 -= self.learning_rate * self.dW2\n",
    "        self.b2 -= self.learning_rate * self.db2\n",
    "\n",
    "    # activation function for hidden layer\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    # activation function for output\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # test the model with test data\n",
    "    def test(self):\n",
    "        Z1 = np.dot( self.X_test, self.W1) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        pred = (A2 > 0.5).astype(float)\n",
    "\n",
    "        print(f\"Test accuracy: {np.mean(pred == self.y_test) * 100:.2f}%\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.1 and epochs=1000: accuracy=95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 50, train loss: 0.2444588119572477\n",
      "epoch 100, train loss: 0.23494592810874734\n",
      "epoch 150, train loss: 0.21947901010232287\n",
      "epoch 200, train loss: 0.20070435267680425\n",
      "epoch 250, train loss: 0.1820776557003048\n",
      "epoch 300, train loss: 0.16498963899456662\n",
      "epoch 350, train loss: 0.1493627035603874\n",
      "epoch 400, train loss: 0.13480501924377206\n",
      "epoch 450, train loss: 0.12112839094784768\n",
      "epoch 500, train loss: 0.10831263991924865\n",
      "epoch 550, train loss: 0.09631048600038668\n",
      "epoch 600, train loss: 0.08511344996972135\n",
      "epoch 650, train loss: 0.07467271967484534\n",
      "epoch 700, train loss: 0.06509366523361806\n",
      "epoch 750, train loss: 0.05639367604844618\n",
      "epoch 800, train loss: 0.04872261099777397\n",
      "epoch 850, train loss: 0.041931370322057106\n",
      "epoch 900, train loss: 0.03600881049560297\n",
      "epoch 950, train loss: 0.03084239494663581\n",
      "Test accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.1)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.1 and epochs=5000: accuracy=96.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 300, train loss: 0.16498963899456662\n",
      "epoch 600, train loss: 0.08511344996972135\n",
      "epoch 900, train loss: 0.03600881049560297\n",
      "epoch 1200, train loss: 0.014246905814059218\n",
      "epoch 1500, train loss: 0.006222533764400692\n",
      "epoch 1800, train loss: 0.0030897444155854005\n",
      "epoch 2100, train loss: 0.0017192748429944366\n",
      "epoch 2400, train loss: 0.001047538607213062\n",
      "epoch 2700, train loss: 0.0006855021381624295\n",
      "epoch 3000, train loss: 0.00047344263078874044\n",
      "epoch 3300, train loss: 0.00034123801809129805\n",
      "epoch 3600, train loss: 0.00025439994045856155\n",
      "epoch 3900, train loss: 0.00019513346881393473\n",
      "epoch 4200, train loss: 0.00015353350127888157\n",
      "epoch 4500, train loss: 0.00012334168868007516\n",
      "epoch 4800, train loss: 0.00010078860043547762\n",
      "Test accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.1, ne=5000)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.01 and epochs=1000: accuracy=61.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 300, train loss: 0.24684850530211744\n",
      "epoch 600, train loss: 0.24298118358770093\n",
      "epoch 900, train loss: 0.23726172057292036\n",
      "Test accuracy: 61.67%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.01)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.01 and epochs=5000: accuracy=83.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 300, train loss: 0.24684850530211744\n",
      "epoch 600, train loss: 0.24298118358770093\n",
      "epoch 900, train loss: 0.23726172057292036\n",
      "epoch 1200, train loss: 0.229256755790356\n",
      "epoch 1500, train loss: 0.21928969864880835\n",
      "epoch 1800, train loss: 0.20812320240516832\n",
      "epoch 2100, train loss: 0.196662253868069\n",
      "epoch 2400, train loss: 0.18546085596035428\n",
      "epoch 2700, train loss: 0.17481308478415858\n",
      "epoch 3000, train loss: 0.16476366528509717\n",
      "epoch 3300, train loss: 0.15522562152590702\n",
      "epoch 3600, train loss: 0.14613959641836233\n",
      "epoch 3900, train loss: 0.13740311086840243\n",
      "epoch 4200, train loss: 0.12900299666169807\n",
      "epoch 4500, train loss: 0.12090419394187611\n",
      "epoch 4800, train loss: 0.1131156737507235\n",
      "Test accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.01, ne=5000)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.9 and epochs=1000: accuracy=96.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 300, train loss: 0.0006962770862129016\n",
      "epoch 600, train loss: 6.979939969569984e-05\n",
      "epoch 900, train loss: 2.1291029765191156e-05\n",
      "Test accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.9)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate=0.9 and epochs=5000: accuracy=96.67%  (no improvement with increamenting number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.24984946785413803\n",
      "epoch 300, train loss: 0.0006962770862129016\n",
      "epoch 600, train loss: 6.979939969569984e-05\n",
      "epoch 900, train loss: 2.1291029765191156e-05\n",
      "epoch 1200, train loss: 9.628621458520082e-06\n",
      "epoch 1500, train loss: 5.313112831365957e-06\n",
      "epoch 1800, train loss: 3.3096475400973767e-06\n",
      "epoch 2100, train loss: 2.233532440936013e-06\n",
      "epoch 2400, train loss: 1.5956205410268718e-06\n",
      "epoch 2700, train loss: 1.1890534165993882e-06\n",
      "epoch 3000, train loss: 9.159109621221551e-07\n",
      "epoch 3300, train loss: 7.245059170458667e-07\n",
      "epoch 3600, train loss: 5.857036296312873e-07\n",
      "epoch 3900, train loss: 4.821356853608939e-07\n",
      "epoch 4200, train loss: 4.0304618139444854e-07\n",
      "epoch 4500, train loss: 3.413494556510384e-07\n",
      "epoch 4800, train loss: 2.9235729506400524e-07\n",
      "Test accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "net = Network(lr=0.9, ne=5000)\n",
    "net.data_split()\n",
    "net.weight_initialization()\n",
    "net.train()\n",
    "net.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
